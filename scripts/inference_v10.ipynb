{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2 as cv\n",
    "import os\n",
    "\n",
    "model = YOLO('/home/kerdizheng/Desktop/icevision/icevision_v1/train3/weights/best.onnx')\n",
    "\n",
    "plots_path = '/home/kerdizheng/Desktop/icevision/temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(img_path):\n",
    "    results = model(img_path, imgsz=800)\n",
    "\n",
    "    boxes = results[0].boxes.data.cpu().tolist()\n",
    "    labels = results[0].boxes.cls.cpu().tolist()\n",
    "\n",
    "    print(boxes)\n",
    "    print(labels)\n",
    "\n",
    "    img = cv.imread(img_path)\n",
    "\n",
    "    for label, box in zip(labels, boxes):\n",
    "        cv.rectangle(\n",
    "            img, \n",
    "            (int(box[0]), int(box[1])),\n",
    "            (int(box[2]), int(box[3])),\n",
    "            color=(0,0,255),\n",
    "            thickness=1\n",
    "        )\n",
    "\n",
    "    \n",
    "    cv.imwrite(os.path.join(plots_path, os.path.basename(img_path)), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/kerdizheng/Desktop/icevision/icevision_v1/train3/weights/best.onnx for ONNX Runtime inference...\n",
      "WARNING ⚠️ Failed to start ONNX Runtime with CUDA. Using CPU...\n",
      "Using ONNX Runtime CPUExecutionProvider\n",
      "\n",
      "image 1/1 /home/kerdizheng/Desktop/icevision/data/valid/images/video3_frame0.png: 864x864 9 players, 356.2ms\n",
      "Speed: 6.8ms preprocess, 356.2ms inference, 0.7ms postprocess per image at shape (1, 3, 864, 864)\n",
      "[[193.4604949951172, 122.71208190917969, 250.71824645996094, 202.7640838623047, 0.7767724990844727, 0.0], [504.31298828125, 187.7971954345703, 573.2272338867188, 267.84027099609375, 0.7256882786750793, 0.0], [590.8347778320312, 272.9807434082031, 654.4566040039062, 384.3087463378906, 0.6840597987174988, 0.0], [21.745771408081055, 107.25154876708984, 83.22175598144531, 182.4069061279297, 0.6788039207458496, 0.0], [678.2392578125, 339.6797180175781, 750.2464599609375, 440.67388916015625, 0.6347365379333496, 0.0], [562.5900268554688, 193.01806640625, 605.2793579101562, 275.65618896484375, 0.5720404982566833, 0.0], [245.45819091796875, 240.6993408203125, 298.3867492675781, 358.93646240234375, 0.5157794952392578, 0.0], [496.8594055175781, 367.62713623046875, 596.6250610351562, 465.0411376953125, 0.5154698491096497, 0.0], [526.1558837890625, 367.22052001953125, 596.5711059570312, 463.3753356933594, 0.3804768919944763, 0.0]]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "run_model(\"/home/kerdizheng/Desktop/icevision/data/valid/images/video3_frame0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base = '/home/ubuntu/YOLO/lngxa_unit 71_rev.b_combined_pg4/lngxa_unit 71_rev.b_combined_pg4_200_inference/input'\n",
    "\n",
    "# for img in os.listdir(base):\n",
    "#     img_path = os.path.join(base, img)\n",
    "\n",
    "#     run_model(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import torch\n",
    "\n",
    "# Load the ONNX model\n",
    "session = ort.InferenceSession('/home/ubuntu/YOLO/projects/Signals_Iter09_v10/train/weights/best.onnx')\n",
    "\n",
    "img_path = '/home/ubuntu/YOLO/scripts/iENG-PID/temp/lngxa_unit 71_rev.b_combined_pg4/Shape_ComplexShapesYOLOv8Processor_Signals/input/7_3600_0_4400_800.png'\n",
    "\n",
    "# Create dummy input matching the input size and format of your model\n",
    "# dummy_input = np.random.randn(1, 3, 800, 800).astype(np.float32)  # Adjust size as necessary\n",
    "img = cv.imread(img_path)\n",
    "\n",
    "img = np.transpose(img, (2, 0, 1))\n",
    "\n",
    "# Run inference\n",
    "outputs = session.run(None, {'images': [img]})\n",
    "\n",
    "print(outputs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "boxes = []\n",
    "\n",
    "for item in outputs[0]:\n",
    "    for prediction in item:\n",
    "        # print(prediction)\n",
    "        x, y, w, h, conf, ID = prediction\n",
    "        print(x, y, w, h, conf, ID)\n",
    "        if conf >= 0.9:\n",
    "            boxes.append([ID, x, y, w, h])\n",
    "\n",
    "# print(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(img_path)\n",
    "for box in boxes:\n",
    "    cv.rectangle(\n",
    "        img,\n",
    "        (int(box[1]), int(box[2])),\n",
    "        (int(box[3]), int(box[4])),\n",
    "        color=(0,0,255),\n",
    "        thickness=1\n",
    "    )\n",
    "\n",
    "cv.imwrite('/home/ubuntu/YOLO/temp_plots/detections.png', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2 as cv\n",
    "from shutil import rmtree\n",
    "\n",
    "base = '/home/ubuntu/YOLO/scripts/iENG-PID/temp'\n",
    "moduleInstanceName = \"Shape_ComplexShapesYOLOv8Processor_Signals\"\n",
    "\n",
    "plots_path = '/home/ubuntu/YOLO/temp_plots'\n",
    "\n",
    "if os.path.exists(plots_path):\n",
    "    rmtree(plots_path)\n",
    "    \n",
    "os.makedirs(plots_path)\n",
    "\n",
    "for file in os.listdir(base):\n",
    "    img_path = os.path.join(base, file, 'graphicsMask.png')\n",
    "    json_path = os.path.join(base, file, f\"{file}.json\")\n",
    "    \n",
    "    img = cv.imread(img_path)\n",
    "    \n",
    "    with open(json_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    for annot in json_data[moduleInstanceName]:\n",
    "        MinX = annot['MinX']\n",
    "        MinY = annot['MinY']\n",
    "        MaxX = annot['MaxX']\n",
    "        MaxY = annot['MaxY']\n",
    "        # label = length_corrected_annot['Value']\n",
    "        \n",
    "        cv.rectangle(\n",
    "            img,\n",
    "            (MinX, MinY),\n",
    "            (MaxX, MaxY),\n",
    "            color = (0,0,255),\n",
    "            thickness=2\n",
    "        )\n",
    "    \n",
    "    cv.imwrite(os.path.join(plots_path, f\"{file}.png\"), img)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU_Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
